---
layout: project
title: "Synch.Live: Emergent art. New science."
subtitle: Building and using an open technology framework to explore collective emergent behaviour in humans.
event: Data Natives Conference
location: City University London
date: "6 May 2022, 12:25"
slides: /assets/files/mis.pm-synchlive.pdf
web: "https://synch.live"
video: "https://www.youtube.com/watch?v=2L5KlpFCoDw&t=768s"
permalink: /talks/2022-synchlive
img: /assets/img/talks/2022-synchlive.png
---

_Abstract._ Synch.Live is a participatory art experience designed to mobilize our human instinct to cooperate, and an open technology research framework that allows scientists to study collective behavior and collaboration.
The work takes inspiration from emergent systems in nature like flocking birds or swarming ants that work together to create something greater than the sum of their parts.

In Synch.Live, players wear headsets equipped with randomly flashing LEDs, which synchronise when the players move together in a coherent, emergent fashion, like a flock of birds.
A state-of-the-art information-theoretical framework [[1]](#1) is used to identify and quantify emergent behaviour based on the players' trajectories.
Each instance of the game generates motion data, which has already been of crucial importance in verifying our theory of emergence.

Together with exploring the state of mind and personalities of participants and how that affects the emergent behaviour, the system provides a rich platform for research.

Synch.Live explores non-verbal communication and exercises deep attention to others, in ways which may cause novel states of mind to emerge. Synch.Live is an inherently participatory experience, in the spirit of 'social sculpture', allowing players from all walks of life to experience first-hand the spontaneous appearance of emergent phenomena.

<br/>

<div class="row">
  <div class="col-1-of-2">
    <video width="100%" preload="auto" autoplay="autoplay" muted="muted" loop="">
        <source src="/assets/files/synchlive-simulate.ogv" type="video/ogg">
    </video>
  </div>
  <div class="col-1-of-2">
    <video width="100%" preload="auto" autoplay="autoplay" muted="muted" loop="" style="border:1px solid #fff">
        <source src="/assets/files/synchlive-footage.ogv" type="video/ogg">
    </video>
</div>
<p>Fig 1. (a) The results of simulating a Kuramoto-Vicsek self-propelled particles model, in the attempt of modelling the collective behaviour and synchrony in Synch.Live, for the purpose of quantifying emergent features with information theory tools. (b) The recorded footage of a group of people playing Synch.Live.</p>
</div>



<a name="1">[1]</a> Fernando Rosas, Pedro Mediano, Henrik Jensen, Anil Seth, Adam Barrett, Robin Carhart-Harris, Daniel Bor (2020). Reconciling emergences: An information-theoretic approach to identify causal emergence in multivariate data. PLoS Computational Biology 16(12).



<p class="text-center">
<b>When: 22 Apr 2022, 14:30</b> <br/>
<b>Where:</b> Engagement Day Conference, Imperial College London<br/>
</p>

